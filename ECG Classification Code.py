# -*- coding: utf-8 -*-
"""LSTMipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ymc7GmwYtBwx4GmjNFVDM1sEi_5diYS9
"""

weimport os
import tensorflow as tf
import pandas as pd

import csv

zip_path = tf.keras.utils.get_file(
    origin='https://www.kaggle.com/datasets/sadmansakib7/ecg-arrhythmia-classification-dataset/download?datasetVersionNumber=1',
    fname='archive(16)',
    extract=True)
csv_path, _ = os.path.splitext(zip_path)

import matplotlib.pyplot as plt
import numpy as np
import sklearn as sk
import seaborn as sns

df = pd.read_csv('INCART 2-lead Arrhythmia Database.csv')

"""# New Section"""

df

df.shape

target = df['type']

df['type']

df.type.value_counts()

df

from sklearn.preprocessing import LabelEncoder
label = LabelEncoder()

df.drop(['record'] , axis=1, inplace=True)

df.type = label.fit_transform(df.type)

df

corr_score=[]
for column1 in df:
  corr_score.append([ df[column1].corr(df[column2]) for column2 in df])

df.type.value_counts()

sns.set(rc={'figure.figsize':(35,35)})

sns.heatmap(corr_score , annot=True , linewidths=0.5)

target = df.type
df.drop(['type'] , axis=1 , inplace=True)

target.value_counts()

df

target

#for i in X:
  #print(X[i].corr(target))

target.shape[0]

import keras 
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

for i in df:
  print(i , df[i].corr(target))

for i in df:
  if(abs(df[i].corr(target))<0.1):
    df.drop(i,axis=1,inplace=True)

df

target.dtype

X=np.array(df)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.1, random_state = 0)
import keras
from keras.layers import Conv1D
from keras.layers import Dense, Activation, Flatten, Conv1D, Dropout, BatchNormalization, MaxPooling1D, LeakyReLU

ms_input_shape = (10,2300,3) #Could someone suggest how I should set the input shape to be?
X_train = np.random.random((10,2300,3))
y_train = np.random.random((10, 5))

model = keras.models.Sequential()
#model.add(tf.keras.layers.InputLayer())
model.add(Conv1D(filters=6, kernel_size=21, strides=1, padding='same', activation='relu',input_shape= ms_input_shape[1:],kernel_initializer=keras.initializers.he_normal()))
model.add(BatchNormalization()) #what is the purpose of this!
model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))
model.add(Conv1D(filters=16, kernel_size=5, strides=1, padding='same',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))
model.add(Flatten())
model.add(Dense(120, activation='relu'))
model.add(Dense(84))
model.add(Dense(5, activation='softmax'))
model.summary()

model.compile(
    optimizer="adam",
    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
    metrics=["accuracy"]
)

model.compile(loss='binary_crossentropy',
			optimizer='Adam',
			metrics=['accuracy'])

X.shape

X = np.random.random((10,2300,3))
target = np.random.random((10, 5))

import tensorflow as tf
model.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['acc'])


callbacks_list = [
    keras.callbacks.ModelCheckpoint(
        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',
        monitor='val_loss', save_best_only=True),
    keras.callbacks.EarlyStopping(monitor='acc', patience=1)]

BATCH_SIZE = 32
EPOCHS = 20

history= model.fit(X,
                    target,
                    batch_size=BATCH_SIZE,
                    epochs=EPOCHS,
                    validation_split=0.2,
                    verbose=1)

def plot_training_results(history):
    """
    Visualize results of the model training using `matplotlib`.

    The visualization will include charts for accuracy and loss, 
    on the training and as well as validation data sets.

    INPUTS:
        history(tf.keras.callbacks.History): 
            Contains data on how the model metrics changed 
            over the course of training.
    
    OUTPUTS: 
        None.
    """
    accuracy = history.history['accuracy']
    accuracy
    validation_accuracy = history.history['val_accuracy']
    validation_accuracy

    loss = history.history['loss']
    loss
    validation_loss = history.history['val_loss']
    validation_loss

    epochs_range = range(epochs)
    epochs_range

    plt.figure(figsize=(20, 8))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, accuracy, label='Training Accuracy')
    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, validation_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()

acc = history.history['acc']
val_acc = history.history['val_acc']
acc = history.history['acc']

val_acc = history.history['val_loss']

loss = history.history['loss']

val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))

plt.subplot(2, 1, 1)

plt.plot(acc, label='Training Accuracy')

plt.plot(val_acc, label='Validation Accuracy')

plt.legend(loc='lower right')

plt.ylabel('Accuracy')

plt.ylim([min(plt.ylim()),1])

plt.title('Training and Validation Accuracy')


plt.subplot(2, 1, 2)

plt.plot(loss, label='Training Loss')

plt.plot(val_loss, label='Validation Loss')

plt.legend(loc='upper right')

plt.ylabel('Cross Entropy')

plt.ylim([0,1.0])

plt.title('Training and Validation Loss')

plt.xlabel('epoch')

plt.show()